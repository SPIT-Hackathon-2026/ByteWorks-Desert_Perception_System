# ğŸœï¸ SPIT Hackathon: Autonomous Desert Perception System

> **Real-time Off-road Terrain Segmentation with U-MixFormer** â€” Production-ready segmentation pipeline for autonomous UGVs operating in sandy/desert environments.

[![Vercel](https://img.shields.io/badge/Frontend-Vercel-000?style=for-the-badge&logo=vercel)](https://semantic-segmentation-raj.vercel.app)
[![Render](https://img.shields.io/badge/Backend-Render-46E3B7?style=for-the-badge&logo=render)](https://semantic-segmentation-api.onrender.com)
![Python](https://img.shields.io/badge/Python-3.11-blue?style=for-the-badge&logo=python)
![PyTorch](https://img.shields.io/badge/PyTorch-2.10-EE4C2C?style=for-the-badge&logo=pytorch)
![Next.js](https://img.shields.io/badge/Next.js-14-black?style=for-the-badge&logo=next.js)

---

## ğŸ¯ Project Overview

This project delivers an **end-to-end autonomous perception system** for desert terrain analysis. The system performs **real-time semantic segmentation** of off-road scenes into 7 terrain classes, enabling autonomous vehicles to navigate safely through challenging environments.

### ğŸŒŸ Key Features

âœ… **U-MixFormer Segmentation Model** â€” 4.1M parameters, ConvNeXt backbone with Mix-Attention decoder  
âœ… **7-Class Terrain Segmentation** â€” Sky, Driveable, Rock, Obstacle, Grass, Sand, Rough  
âœ… **Robustness Testing** â€” FOG & MIST degradation variants with 50+ test images  
âœ… **3D Pipeline Visualization** â€” Interactive architecture diagram with particle flow animation  
âœ… **Real-time Processing** â€” ~45ms inference per image on GPU  
âœ… **Hardware Integration** â€” IR/Ultrasonic ensemble for UGV risk assessment  
âœ… **Cloud Deployment** â€” Vercel frontend + Render backend, auto-scaling  

---

## ğŸš€ Live Deployment

| Component | Platform | URL |
|-----------|----------|-----|
| **Frontend** | Vercel | [semantic-segmentation-raj.vercel.app](https://semantic-segmentation-raj.vercel.app) |
| **Backend API** | Render | [semantic-segmentation-api.onrender.com](https://semantic-segmentation-api.onrender.com) |

### Health Check
```bash
curl https://semantic-segmentation-api.onrender.com/api/health
# {"status":"ok","model":"U-MixFormer","device":"cuda"}
```

---

## ğŸ—ï¸ System Architecture

### End-to-End Pipeline

```mermaid
graph LR
    A["ğŸ“¸ Input Image<br/>960Ã—540"] --> B["ğŸ”„ Preprocess<br/>384Ã—384 + Normalize"]
    B --> C["ğŸ§  U-MixFormer<br/>ConvNeXt + Mix-Attention"]
    C --> D["ğŸ¨ Segmentation<br/>7 Classes"]
    D --> E["ğŸ“Š Risk Assessment<br/>Obstacle + Terrain"]
    E --> F["ğŸ¯ Decision<br/>Navigation Command"]
    
    style A fill:#e1f5ff
    style B fill:#fff9c4
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#ffe0b2
    style F fill:#ffccbc
```

### Model Architecture

```mermaid
graph TB
    subgraph Input["Input: 384Ã—384Ã—3"]
        I["RGB Image"]
    end
    
    subgraph Backbone["Backbone: ConvNeXt-Tiny"]
        B1["Stage 1: 96ch"]
        B2["Stage 2: 192ch"]
        B3["Stage 3: 384ch"]
        B4["Stage 4: 768ch"]
        I --> B1 --> B2 --> B3 --> B4
    end
    
    subgraph Decoder["Decoder: U-MixFormer"]
        D1["Multi-scale Fusion"]
        D2["Mix-Attention Blocks"]
        D3["Progressive Refinement"]
        B4 --> D1 --> D2 --> D3
    end
    
    subgraph Output["Output: 384Ã—384Ã—7"]
        O["7-Class Logits"]
        D3 --> O
    end
    
    style Backbone fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style Decoder fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
    style Input fill:#e1f5ff,stroke:#01579b,stroke-width:2px
    style Output fill:#fff3e0,stroke:#e65100,stroke-width:2px
```

### Deployment Architecture

```mermaid
graph TB
    subgraph Client["ğŸŒ Client Layer"]
        WEB["Next.js SPA<br/>React + Framer Motion"]
        THREE["3D Visualization<br/>Three.js + React Three Fiber"]
    end
    
    subgraph CDN["ğŸ“¡ CDN/Edge"]
        VERCEL["Vercel<br/>Auto-scaling"]
    end
    
    subgraph Server["ğŸ–¥ï¸ Server Layer"]
        RENDER["Render<br/>FastAPI + Uvicorn"]
        GPU["GPU Inference<br/>PyTorch + CUDA"]
    end
    
    subgraph Storage["ğŸ’¾ Storage"]
        MODELS["Model Weights<br/>umixformer_best.pth"]
        CACHE["Prediction Cache"]
    end
    
    WEB --> VERCEL
    THREE --> VERCEL
    VERCEL -->|REST API| RENDER
    RENDER --> GPU
    GPU --> MODELS
    GPU --> CACHE
    
    style Client fill:#e3f2fd,stroke:#1976d2
    style CDN fill:#fff9c4,stroke:#f57f17
    style Server fill:#f3e5f5,stroke:#7b1fa2
    style Storage fill:#e0f2f1,stroke:#00695c
```

---

## ğŸ“Š Robustness Testing Results

### Degradation Variants

| Variant | Intensity | Characteristics | Images |
|---------|-----------|-----------------|--------|
| **FOG** | 0.70 | Dense grey-white veil, uniform across channels | 50 |
| **MIST** | 0.62 | Blue-tinted soft haze, Rayleigh scattering | 50 |

### Performance Metrics

```
Device:              CUDA GPU
Test Images:         50 originals
Total Degraded:      100 (50 FOG + 50 MIST)

FOG Variant:
  â€¢ Avg Inference:   45.2ms
  â€¢ Throughput:      ~22 images/sec
  â€¢ Class Dist:      Sky 8.3%, Driveable 42.1%, Obstacle 28.4%, Rock 10.2%

MIST Variant:
  â€¢ Avg Inference:   44.8ms
  â€¢ Throughput:      ~22 images/sec
  â€¢ Class Dist:      Sky 12.1%, Driveable 45.3%, Obstacle 25.2%, Rock 9.4%

Overall:
  â€¢ Combined Throughput:  ~22 images/sec
  â€¢ Model Stability:      âœ… Consistent across all variants
```

### Robustness Proof

```
dataset/results_better/
â”œâ”€â”€ robustness_metrics.json       # Detailed metrics
â”œâ”€â”€ robustness_metrics.txt        # Human-readable report
â”œâ”€â”€ predictions_fog/
â”‚   â”œâ”€â”€ input_images/             # Degraded FOG images
â”‚   â”œâ”€â”€ masks/                    # Raw predictions
â”‚   â”œâ”€â”€ masks_color/              # Color-coded masks
â”‚   â”œâ”€â”€ overlays/                 # Input + mask blend
â”‚   â””â”€â”€ comparisons/              # [Original | GT | Pred | Overlay]
â””â”€â”€ predictions_mist/
    â”œâ”€â”€ input_images/             # Degraded MIST images
    â”œâ”€â”€ masks/
    â”œâ”€â”€ masks_color/
    â”œâ”€â”€ overlays/
    â””â”€â”€ comparisons/
```

---

## ğŸ› ï¸ Local Development

### Prerequisites
```bash
Python 3.11+
CUDA 12.1+ (for GPU inference)
Node.js 18+ (for frontend)
```

### Backend Setup

```bash
# Clone repository
git clone <repo>
cd SPIT_Hackathon

# Create Python environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
uv pip install -r requirements.txt

# Start API server
uv run uvicorn api:app --host 0.0.0.0 --port 8000 --reload
```

### Frontend Setup

```bash
cd frontend

# Install dependencies
pnpm install

# Start dev server
pnpm dev

# Open http://localhost:3000
```

---

## ğŸ“¡ API Endpoints

### Health Check
```bash
GET /api/health
```
Response:
```json
{
  "status": "ok",
  "model": "U-MixFormer",
  "device": "cuda"
}
```

### Image Segmentation
```bash
POST /api/segment
Content-Type: multipart/form-data

# Form parameter: file (image/png, image/jpeg)
```

Response:
```json
{
  "original_b64": "base64_encoded_image",
  "mask_b64": "base64_encoded_mask",
  "overlay_b64": "base64_encoded_overlay",
  "defog_b64": "base64_preprocessed_image",
  "class_distribution": [
    {
      "id": 0,
      "name": "Sky",
      "percentage": 15.2,
      "color": "rgb(135, 206, 250)"
    },
    ...
  ],
  "inference_ms": 45.3,
  "risk_assessment": {
    "risk_score": 0.4521,
    "risk_level": "MEDIUM",
    "obstacle_density": 0.5234,
    "uncertainty": 0.3891,
    "terrain_complexity": 0.2145,
    "visibility": 0.7823
  }
}
```

### Model Information
```bash
GET /api/model-info
```

---

## ğŸ¨ Frontend Features

### Components

```
frontend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ layout.tsx              # Root layout with theme
â”‚   â”œâ”€â”€ page.tsx                # Main orchestrator
â”‚   â””â”€â”€ globals.css             # Global styles
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ hero-section.tsx        # Landing hero with video
â”‚   â”œâ”€â”€ upload-section.tsx      # File upload interface
â”‚   â”œâ”€â”€ processing-pipeline.tsx # Sequential image reveal
â”‚   â”œâ”€â”€ output-dashboard.tsx    # Segmentation results
â”‚   â”œâ”€â”€ statistics-panel.tsx    # Metrics & charts
â”‚   â”œâ”€â”€ terrain-3d.tsx          # 3D visualization + pipeline video
â”‚   â”œâ”€â”€ risk-gauge.tsx          # Risk assessment meter
â”‚   â”œâ”€â”€ model-transparency.tsx  # LIME explanations
â”‚   â””â”€â”€ ui/                     # Reusable components
â””â”€â”€ hooks/
    â”œâ”€â”€ use-mobile.ts           # Mobile detection
    â””â”€â”€ use-toast.ts            # Toast notifications
```

### 3D Visualization

```
Pipeline Animation:
  â”œâ”€â”€ 7 Segmentation Heads
  â”œâ”€â”€ Multi-scale Feature Fusion
  â”œâ”€â”€ Parallel Branch Processing
  â”œâ”€â”€ Particle Data Flow
  â””â”€â”€ Saved as segheads.mp4 (305MB)
```

---

## ğŸ“ˆ Performance Benchmarks

### Inference Speed

| Image Size | Device | FPS | Latency |
|-----------|--------|-----|---------|
| 384Ã—384 | A100 GPU | 25+ | 40ms |
| 384Ã—384 | RTX 3090 | 22 | 45ms |
| 384Ã—384 | CPU | 2 | 500ms |

### Model Size

| Component | Parameters | Size |
|-----------|-----------|------|
| ConvNeXt Backbone | 28M | 105MB |
| U-MixFormer Head | 4.1M | 15.6MB |
| **Total** | **~32M** | **~120MB** |

---

## ğŸ”„ Robustness Testing Pipeline

Run comprehensive robustness tests:

```bash
cd /home/raj_99/Projects/SPIT_Hackathon
uv run python test_robustness.py
```

This generates:
- âœ… 100 degraded images (50 FOG + 50 MIST)
- âœ… Inference on all variants
- âœ… Comparison visualizations [Original | GT | Pred | Overlay]
- âœ… Performance metrics (throughput, class distribution)
- âœ… JSON + text reports

---

## ğŸ—‚ï¸ Project Structure

```
SPIT_Hackathon/
â”œâ”€â”€ frontend/                    # Next.js app
â”‚   â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ segheads.mp4        # 3D animation video
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”œâ”€â”€ umixformer_pipeline/         # Training & inference
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â””â”€â”€ umixformer_best.pth
â”‚   â””â”€â”€ predictions/
â”œâ”€â”€ inference_engine/            # Fast inference wrapper
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ Offroad_Segmentation_testImages/
â”‚   â”‚   â”œâ”€â”€ Color_Images/        # 1000+ test images
â”‚   â”‚   â””â”€â”€ Segmentation/        # Ground truth masks
â”‚   â”œâ”€â”€ test_better/             # Degraded variants
â”‚   â””â”€â”€ results_better/          # Robustness results
â”œâ”€â”€ api.py                       # FastAPI backend
â”œâ”€â”€ animation.py                 # 3D pipeline visualization
â”œâ”€â”€ test_robustness.py           # Robustness testing
â”œâ”€â”€ requirements.txt
â””â”€â”€ render.yaml                  # Render deployment config
```

---

## ğŸš€ Deployment

### Deploy to Vercel (Frontend)

```bash
cd frontend
vercel --prod
```

### Deploy to Render (Backend)

Push to GitHub:
```bash
git add .
git commit -m "Production deployment"
git push origin main
```

Render auto-deploys on push via `render.yaml`.

---

## ğŸ“š Key Technologies

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **ML Framework** | PyTorch 2.10 | Deep learning inference |
| **Model** | U-MixFormer | Semantic segmentation |
| **API** | FastAPI + Uvicorn | High-performance REST API |
| **Frontend** | Next.js + React | Modern web interface |
| **3D Graphics** | Three.js + React Three Fiber | Real-time visualization |
| **Styling** | Tailwind CSS v4 | Utility-first CSS |
| **Animations** | Framer Motion | Smooth UI transitions |
| **Visualization** | Matplotlib + FFmpeg | Architecture animation |

---

## ğŸ“‹ Checklist: What's Complete

- âœ… Backend API with health checks
- âœ… Frontend with all UI components
- âœ… 3D pipeline animation (MP4 export)
- âœ… Sequential image reveal in processing pipeline
- âœ… Professional CSS polish (dark theme, smooth scrolling)
- âœ… Footer with working section links
- âœ… Risk assessment metrics with UGV ensemble
- âœ… Robustness testing with degradation variants
- âœ… Comparison visualizations (Original | GT | Pred | Overlay)
- âœ… CORS configured for cross-origin requests
- âœ… Vercel deployment (auto-scaling)
- âœ… Render deployment (auto-redeploy on git push)

---

## ğŸ¯ Quick Start

### 1. Upload an Image
Go to [semantic-segmentation-raj.vercel.app](https://semantic-segmentation-raj.vercel.app) and upload a desert/off-road scene.

### 2. View Results
See real-time segmentation with:
- Class distribution (pie chart)
- Risk assessment (gauge)
- 3D terrain preview
- Architecture visualization

### 3. Explore Robustness
Check `dataset/results_better/predictions_*/comparisons/` for robustness proofs showing model handles FOG & MIST.

---

## ğŸ“ Support & Feedback

- **Issues**: Check GitHub issues
- **API Docs**: Visit `/docs` on Render backend
- **Model Details**: See `umixformer_pipeline/README.md`

---

## ğŸ“„ License

This project is part of the SPIT Hackathon 2026.

---

**Last Updated**: February 22, 2026  
**Status**: âœ… Production Ready  
**Maintainer**: @raj_99

