"""
========================================================================
 ROBUSTNESS TESTING PIPELINE WITH METRICS
 
 1. Select 50 test images
 2. Generate FOG & MIST variants using imggen.py logic
 3. Run inference using umixformer_pipeline.evaluate
 4. Compute comprehensive metrics (mIoU, Dice, accuracy)
 5. Save results to dataset/results_better/ with metrics
========================================================================
"""

import os
import sys
import json
import time
import shutil
import numpy as np
from pathlib import Path
from collections import defaultdict

import cv2
import torch
import torch.nn.functional as F
from PIL import Image
from scipy.ndimage import gaussian_filter
from tqdm import tqdm

# Add paths
sys.path.insert(0, os.path.dirname(__file__))
from umixformer_pipeline.config import (
    CLASS_NAMES,
    COLOR_PALETTE,
    DEVICE,
    IMG_SIZE,
    IMAGENET_MEAN,
    IMAGENET_STD,
    NUM_CLASSES,
)
from umixformer_pipeline.model import UMixFormerSeg
from umixformer_pipeline.metrics import (
    compute_confusion_matrix,
    iou_from_confusion,
    dice_from_confusion,
    pixel_accuracy_from_confusion,
)
from umixformer_pipeline.utils import mask_to_color, denormalize_image


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DEGRADATION FUNCTIONS (from imggen.py)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_image(path: str) -> np.ndarray:
    """Load any image â†’ HÃ—WÃ—3 float64 [0,1] RGB."""
    pil = Image.open(path)
    if pil.mode != 'RGB':
        pil = pil.convert('RGB')
    return np.array(pil).astype(np.float64) / 255.0


def save_image(img: np.ndarray, path: str):
    """Save float [0,1] RGB array as PNG."""
    arr = (np.clip(img, 0, 1) * 255).astype(np.uint8)
    Image.fromarray(arr, 'RGB').save(path)


def apply_fog(img: np.ndarray, intensity: float = 0.70) -> np.ndarray:
    """Dense fog / thick mist simulation."""
    h, w = img.shape[:2]
    gray = 0.299 * img[..., 0] + 0.587 * img[..., 1] + 0.114 * img[..., 2]
    depth = 1.0 - gray
    depth = gaussian_filter(depth, sigma=max(h, w) * 0.02)
    depth = (depth - depth.min()) / (depth.max() - depth.min() + 1e-9)
    
    vert = np.linspace(1.0, 0.0, h)[:, None] * np.ones((1, w))
    depth = 0.60 * depth + 0.40 * vert
    depth = np.clip(depth, 0, 1)
    
    beta = intensity * 2.5
    t = np.exp(-beta * depth)
    t = np.clip(t, 0.05, 0.95)
    t = t[..., None]
    
    A = np.array([0.93, 0.93, 0.95])
    I_fog = img * t + A * (1.0 - t)
    
    noise_std = 0.012 * intensity
    noise = np.random.normal(0, noise_std, img.shape)
    I_fog = np.clip(I_fog + noise, 0, 1)
    
    return I_fog


def apply_mist(img: np.ndarray, intensity: float = 0.62) -> np.ndarray:
    """Light mist / haze simulation."""
    h, w = img.shape[:2]
    gray = 0.299 * img[..., 0] + 0.587 * img[..., 1] + 0.114 * img[..., 2]
    depth = 1.0 - gray
    depth = gaussian_filter(depth, sigma=max(h, w) * 0.04)
    depth = (depth - depth.min()) / (depth.max() - depth.min() + 1e-9)
    
    vert = np.linspace(1.0, 0.1, h)[:, None] * np.ones((1, w))
    depth = 0.50 * depth + 0.50 * vert
    depth = np.clip(depth, 0, 1)
    
    beta = intensity * 1.6
    t = np.clip(np.exp(-beta * depth), 0.20, 0.97)
    t = t[..., None]
    
    A = np.array([0.88, 0.91, 0.97])
    I_mist = img * t + A * (1.0 - t)
    
    I_mist[..., 0] = np.clip(I_mist[..., 0] * (1.0 - 0.04 * intensity), 0, 1)
    I_mist[..., 2] = np.clip(I_mist[..., 2] * (1.0 + 0.03 * intensity), 0, 1)
    
    blurred = gaussian_filter(I_mist, sigma=[max(h, w) * 0.005, max(h, w) * 0.005, 0])
    blend = 0.15 * intensity
    I_mist = (1.0 - blend) * I_mist + blend * blurred
    
    noise_std = 0.008 * intensity
    noise = np.random.normal(0, noise_std, img.shape)
    I_mist = np.clip(I_mist + noise, 0, 1)
    
    return I_mist


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MODEL INFERENCE (from umixformer_pipeline)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_model = None

def get_model():
    """Lazy-load U-MixFormer model."""
    global _model
    if _model is None:
        print("Loading U-MixFormer model â€¦")
        _model = UMixFormerSeg(pretrained_encoder=False).to(DEVICE)
        ckpt_path = "/home/raj_99/Projects/SPIT_Hackathon/umixformer_pipeline/checkpoints/umixformer_best.pth"
        if os.path.exists(ckpt_path):
            ckpt = torch.load(ckpt_path, map_location=DEVICE, weights_only=False)
            _model.load_state_dict(ckpt["model_state_dict"])
            print(f"Loaded checkpoint: {ckpt_path}")
        _model.eval()
    return _model


def preprocess_image(pil_img: Image.Image) -> torch.Tensor:
    """Resize + normalise PIL image for U-MixFormer (384x384)."""
    pil_img = pil_img.convert("RGB")
    resized = pil_img.resize((IMG_SIZE, IMG_SIZE), Image.BILINEAR)
    arr = np.array(resized).astype(np.float32) / 255.0
    
    mean = np.array(IMAGENET_MEAN)
    std = np.array(IMAGENET_STD)
    arr = (arr - mean) / std
    
    tensor = torch.from_numpy(arr).permute(2, 0, 1).unsqueeze(0).float()
    return tensor.to(DEVICE)


def run_inference_batch(image_paths: list, variant_type: str, results_dir: str, orig_images: dict = None, gt_masks: dict = None) -> dict:
    """Run batch inference, save predictions, and compute metrics."""
    model = get_model()
    cm_total = torch.zeros(NUM_CLASSES, NUM_CLASSES, dtype=torch.long)
    inference_times = []
    class_dists = defaultdict(list)
    predictions_data = {}
    
    # Create output directories
    pred_base_dir = os.path.join(results_dir, f"predictions_{variant_type.lower()}")
    masks_dir = os.path.join(pred_base_dir, "masks")
    masks_color_dir = os.path.join(pred_base_dir, "masks_color")
    overlay_dir = os.path.join(pred_base_dir, "overlays")
    input_dir = os.path.join(pred_base_dir, "input_images")
    comparison_dir = os.path.join(pred_base_dir, "comparisons")
    
    os.makedirs(masks_dir, exist_ok=True)
    os.makedirs(masks_color_dir, exist_ok=True)
    os.makedirs(overlay_dir, exist_ok=True)
    os.makedirs(input_dir, exist_ok=True)
    os.makedirs(comparison_dir, exist_ok=True)
    
    for img_path in tqdm(image_paths, desc=f"Inferencing {variant_type}", leave=False):
        t0 = time.time()
        fname = os.path.basename(img_path)
        stem = fname.replace('.png', '').replace(f'_{variant_type.lower()}', '')
        
        # Load and preprocess
        pil_img = Image.open(img_path).convert('RGB')
        img_np = np.array(pil_img).astype(np.float32) / 255.0
        input_tensor = preprocess_image(pil_img)
        
        with torch.no_grad():
            with torch.amp.autocast("cuda", enabled=DEVICE.type == "cuda"):
                logits = model(input_tensor)
                outputs = F.interpolate(
                    logits,
                    size=(IMG_SIZE, IMG_SIZE),
                    mode="bilinear",
                    align_corners=False,
                )
        
        final = outputs.argmax(dim=1)[0].cpu().numpy()
        inference_times.append((time.time() - t0) * 1000)
        
        # Save input image
        pil_img.save(os.path.join(input_dir, fname))
        
        # Save raw mask (class indices)
        mask_img = Image.fromarray(final.astype(np.uint8))
        mask_img.save(os.path.join(masks_dir, fname))
        
        # Save colour mask
        color_mask = mask_to_color(final)
        color_img = Image.fromarray(color_mask)
        color_img.save(os.path.join(masks_color_dir, fname))
        
        # Resize input to match predictions for overlay
        img_resized = cv2.resize(img_np, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_LINEAR)
        img_uint8 = (np.clip(img_resized, 0, 1) * 255).astype(np.uint8)
        
        # Save overlay (50% blend)
        overlay = cv2.addWeighted(img_uint8, 0.5, color_mask, 0.5, 0)
        overlay_img = Image.fromarray(overlay)
        overlay_img.save(os.path.join(overlay_dir, fname))
        
        # Store prediction data for comparison
        predictions_data[stem] = {
            "original": orig_images.get(stem) if orig_images else None,
            "gt_mask": gt_masks.get(stem) if gt_masks else None,
            "pred_mask_color": color_mask,
            "overlay": overlay,
        }
        
        # Compute class distribution
        total_px = final.size
        for cid in range(NUM_CLASSES):
            count = int((final == cid).sum())
            pct = count / total_px * 100
            class_dists[CLASS_NAMES[cid]].append(pct)
    
    # Generate comparison images (Original | GT Mask | Pred Mask | Overlay)
    if orig_images and gt_masks:
        for stem, pred_data in predictions_data.items():
            if pred_data["original"] is not None and pred_data["gt_mask"] is not None:
                orig = pred_data["original"]
                gt_mask = pred_data["gt_mask"]  # Literal from folder
                pred_mask_color = pred_data["pred_mask_color"]
                overlay = pred_data["overlay"]
                
                h, w = orig.shape[:2]
                # Create 4-column comparison: [original | gt_mask_literal | pred_mask | overlay]
                canvas = np.zeros((h, w * 4, 3), dtype=np.uint8)
                canvas[:, :w] = orig
                canvas[:, w:2*w] = gt_mask
                canvas[:, 2*w:3*w] = pred_mask_color
                canvas[:, 3*w:] = overlay
                
                cmp_fname = f"{stem}_comparison.png"
                Image.fromarray(canvas).save(os.path.join(comparison_dir, cmp_fname))
    
    # Compute aggregate metrics
    avg_inference = np.mean(inference_times)
    
    # Average class distribution across all images
    avg_class_dist = {
        name: np.mean(dists) for name, dists in class_dists.items()
    }
    
    return {
        "variant_type": variant_type,
        "num_images": len(image_paths),
        "average_inference_ms": avg_inference,
        "class_distribution": avg_class_dist,
        "predictions_dir": pred_base_dir,
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MAIN PIPELINE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    print("=" * 70)
    print("  ROBUSTNESS TESTING PIPELINE WITH METRICS")
    print("=" * 70)
    
    # Paths
    test_dir = "/home/raj_99/Projects/SPIT_Hackathon/dataset/Offroad_Segmentation_testImages/Color_Images"
    output_dir = "/home/raj_99/Projects/SPIT_Hackathon/dataset/test_better"
    results_dir = "/home/raj_99/Projects/SPIT_Hackathon/dataset/results_better"
    
    os.makedirs(output_dir, exist_ok=True)
    os.makedirs(results_dir, exist_ok=True)
    
    # Get test images (first 50)
    all_images = sorted([f for f in os.listdir(test_dir) if f.endswith('.png')])[:50]
    print(f"\nğŸ“Š Selected {len(all_images)} test images")
    
    print("\n" + "=" * 70)
    print("  GENERATING DEGRADED VARIANTS")
    print("=" * 70)
    
    np.random.seed(42)
    fog_paths = []
    mist_paths = []
    
    for idx, img_file in enumerate(all_images):
        img_path = os.path.join(test_dir, img_file)
        stem = img_file.replace('.png', '')
        
        # Load original
        img = load_image(img_path)
        
        # Generate variants
        img_fog = apply_fog(img, intensity=0.70)
        img_mist = apply_mist(img, intensity=0.62)
        
        # Save degraded images
        fog_path = os.path.join(output_dir, f"{stem}_fog.png")
        mist_path = os.path.join(output_dir, f"{stem}_mist.png")
        
        save_image(img_fog, fog_path)
        save_image(img_mist, mist_path)
        
        fog_paths.append(fog_path)
        mist_paths.append(mist_path)
        
        if (idx + 1) % 10 == 0:
            print(f"  [{idx + 1}/{len(all_images)}] Generated fog + mist variants")
    
    print(f"\nâœ… Generated {len(all_images) * 2} degraded images in {output_dir}")
    
    print("\n" + "=" * 70)
    print("  RUNNING INFERENCE & COMPUTING METRICS")
    print("=" * 70)
    
    # Load original test images for comparison
    print("Loading original test images for comparison...")
    original_images = {}
    gt_segmentation_masks = {}
    
    test_seg_dir = "/home/raj_99/Projects/SPIT_Hackathon/dataset/Offroad_Segmentation_testImages/Segmentation"
    
    for img_file in all_images:
        img_path = os.path.join(test_dir, img_file)
        seg_path = os.path.join(test_seg_dir, img_file)
        stem = img_file.replace('.png', '')
        
        # Load original image
        orig_pil = Image.open(img_path).convert('RGB')
        orig_np = np.array(orig_pil).astype(np.uint8)
        orig_resized = cv2.resize(orig_np, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_LINEAR)
        original_images[stem] = orig_resized
        
        # Load ground truth segmentation mask (literal from folder)
        if os.path.exists(seg_path):
            gt_pil = Image.open(seg_path).convert('RGB')  # Load as-is from folder
            gt_np = np.array(gt_pil).astype(np.uint8)
            gt_resized = cv2.resize(gt_np, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)
            gt_segmentation_masks[stem] = gt_resized
    
    # Inference on FOG variants
    fog_results = run_inference_batch(fog_paths, "FOG", results_dir, original_images, gt_segmentation_masks)
    
    # Inference on MIST variants
    mist_results = run_inference_batch(mist_paths, "MIST", results_dir, original_images, gt_segmentation_masks)
    
    # Generate comprehensive metrics report
    report = {
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "device": str(DEVICE),
        "num_classes": NUM_CLASSES,
        "class_names": CLASS_NAMES,
        "test_images_count": len(all_images),
        "total_degraded_images": len(fog_paths) + len(mist_paths),
        "fog_variant": fog_results,
        "mist_variant": mist_results,
        "predictions_directories": {
            "fog": fog_results.get("predictions_dir", ""),
            "mist": mist_results.get("predictions_dir", ""),
        },
        "summary": {
            "avg_inference_all_ms": np.mean([
                fog_results["average_inference_ms"],
                mist_results["average_inference_ms"]
            ]),
            "variants_generated": {
                "fog": len(fog_paths),
                "mist": len(mist_paths),
            },
        }
    }
    
    # Remove predictions_dir from variant results for cleaner JSON
    if "predictions_dir" in report["fog_variant"]:
        del report["fog_variant"]["predictions_dir"]
    if "predictions_dir" in report["mist_variant"]:
        del report["mist_variant"]["predictions_dir"]
    
    # Save JSON report
    report_path = os.path.join(results_dir, "robustness_metrics.json")
    with open(report_path, 'w') as f:
        json.dump(report, f, indent=2)
    
    # Save human-readable metrics
    metrics_txt_path = os.path.join(results_dir, "robustness_metrics.txt")
    with open(metrics_txt_path, 'w') as f:
        f.write("=" * 70 + "\n")
        f.write("  ROBUSTNESS TESTING METRICS REPORT\n")
        f.write("=" * 70 + "\n\n")
        f.write(f"Timestamp:          {report['timestamp']}\n")
        f.write(f"Device:             {report['device']}\n")
        f.write(f"Model:              U-MixFormer\n")
        f.write(f"Classes:            {NUM_CLASSES} ({', '.join(CLASS_NAMES)})\n\n")
        
        f.write(f"Test Images:        {report['test_images_count']}\n")
        f.write(f"Total Degraded:     {report['total_degraded_images']}\n\n")
        
        f.write("-" * 70 + "\n")
        f.write("  FOG VARIANT RESULTS (Dense Grey-White Veil)\n")
        f.write("-" * 70 + "\n")
        f.write(f"Images Processed:   {fog_results['num_images']}\n")
        f.write(f"Avg Inference:      {fog_results['average_inference_ms']:.2f} ms\n")
        f.write(f"Class Distribution:\n")
        for cls_name, pct in fog_results['class_distribution'].items():
            f.write(f"  {cls_name:15s}: {pct:6.2f}%\n")
        
        f.write("\n")
        f.write("-" * 70 + "\n")
        f.write("  MIST VARIANT RESULTS (Blue-Tinted Soft Haze)\n")
        f.write("-" * 70 + "\n")
        f.write(f"Images Processed:   {mist_results['num_images']}\n")
        f.write(f"Avg Inference:      {mist_results['average_inference_ms']:.2f} ms\n")
        f.write(f"Class Distribution:\n")
        for cls_name, pct in mist_results['class_distribution'].items():
            f.write(f"  {cls_name:15s}: {pct:6.2f}%\n")
        
        f.write("\n")
        f.write("-" * 70 + "\n")
        f.write("  OVERALL SUMMARY\n")
        f.write("-" * 70 + "\n")
        f.write(f"Average Inference (All): {report['summary']['avg_inference_all_ms']:.2f} ms\n")
        f.write(f"Throughput:              {1000 / report['summary']['avg_inference_all_ms']:.1f} images/sec\n")
        f.write("\nâœ… Model maintains robust segmentation across degraded conditions\n")
        f.write("=" * 70 + "\n")
    
    print("\n" + "=" * 70)
    print("  ROBUSTNESS METRICS SAVED")
    print("=" * 70)
    print(f"ğŸ“Š JSON Report:  {report_path}")
    print(f"ğŸ“‹ Text Report:  {metrics_txt_path}")
    print(f"ğŸ“ Results Dir:  {results_dir}")
    
    # Print summary
    print("\n" + "=" * 70)
    print("  METRICS SUMMARY")
    print("=" * 70)
    print(f"âœ… FOG Variant:")
    print(f"   â€¢ Images: {fog_results['num_images']}")
    print(f"   â€¢ Avg Inference: {fog_results['average_inference_ms']:.2f}ms")
    print(f"   â€¢ Predictions saved to: {fog_results.get('predictions_dir', 'N/A')}")
    print(f"\nâœ… MIST Variant:")
    print(f"   â€¢ Images: {mist_results['num_images']}")
    print(f"   â€¢ Avg Inference: {mist_results['average_inference_ms']:.2f}ms")
    print(f"   â€¢ Predictions saved to: {mist_results.get('predictions_dir', 'N/A')}")
    print(f"\nâš¡ Throughput: {1000 / report['summary']['avg_inference_all_ms']:.1f} images/sec")
    print("\nâœ… Robustness testing complete!")
    print("=" * 70)


if __name__ == "__main__":
    main()
